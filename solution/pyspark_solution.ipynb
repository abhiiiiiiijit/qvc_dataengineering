{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d9d79b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, count, when, isnull\n",
    "from pyspark.sql.types import DoubleType, LongType,IntegerType, DateType, DecimalType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "640c0bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ArticleTransaction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7940d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files with inferred schema and header\n",
    "articles_df = spark.read.csv(\"../article.csv\", header=True, inferSchema=False)\n",
    "transactions_df = spark.read.csv(\"../transactions.csv\", header=True, inferSchema=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a151d6",
   "metadata": {},
   "source": [
    "## Article DF inital exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b90abfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles DataFrame:\n",
      "+-------------------+-------------------------+---------------------------+----------+--------------------+----------------------+--------------------+--------------------------------+-------------------+-------------------+\n",
      "|ARTICLE_ID0MATERIAL|ARTICLE_COLOR_ID0RT_COLOR|ARTICLE_GROUP_ID0RT_CONFMAT|EAN0EANUPC|   DESCRIPTION0TXTMD|BRAND_NAME/SOL/MDPROD1|PICTURE_PATH0EXT_URL|INITIAL_SEASON_NAME/SOL/FMSSEASO|CURRENT_SEASON_NAME|MATL_TYPE0MATL_TYPE|\n",
      "+-------------------+-------------------------+---------------------------+----------+--------------------+----------------------+--------------------+--------------------------------+-------------------+-------------------+\n",
      "| 000000000001282247|                     null|                       null|      null|d3dd68a11f543d039...|                    75|                null|                          202008|             202008|               ZMO3|\n",
      "| 000000000001282474|                     null|                       null|      null|d6045a9b489ed9fab...|                    75|                null|                          202010|             202010|               ZMO4|\n",
      "| 000000000002040465|                     null|                       null|      null|2200051f109fd164f...|                    10|                null|                          202007|             202008|               ZMO3|\n",
      "| 000000000002041285|                     null|                       null|      null|8a9eb4021fd0d70a8...|                    50|                null|                          202007|             202007|               ZMO3|\n",
      "| 000000000002041681|                     null|                       null|      null|eb1fb78047d6a068f...|                    10|                null|                          202008|             202008|               ZMO3|\n",
      "+-------------------+-------------------------+---------------------------+----------+--------------------+----------------------+--------------------+--------------------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Count of Articles DataFrame: 223893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Article IDs in Articles DataFrame: 223893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate ARTICLE_ID0MATERIAL rows: 0\n",
      "Is Article ID having null values? False\n",
      "Is Article ID having empty values? False\n",
      "Is Article ID having empty null strings? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Articles DataFrame:\")\n",
    "articles_df.show(5)\n",
    "#print(\"Articles DataFrame Schema:\")\n",
    "#articles_df.printSchema()\n",
    "print(\"Count of Articles DataFrame:\", articles_df.count())\n",
    "print(\"Unique Article IDs in Articles DataFrame:\", articles_df.select(\"ARTICLE_ID0MATERIAL\").distinct().count())\n",
    "# 4.1 Check for duplicate keys in ARTICLE\n",
    "dup_articles = articles_df.groupBy(\"ARTICLE_ID0MATERIAL\").count().filter(col(\"count\") > 1)\n",
    "print(\"Duplicate ARTICLE_ID0MATERIAL rows:\", dup_articles.count())\n",
    "\n",
    "print(\"Is Article ID having null values?\", articles_df.filter(col(\"ARTICLE_ID0MATERIAL\").isNull()).count() > 0)\n",
    "print(\"Is Article ID having empty values?\", articles_df.filter(col(\"ARTICLE_ID0MATERIAL\") == \"\").count() > 0)\n",
    "print(\"Is Article ID having empty null strings?\", articles_df.filter(col(\"ARTICLE_ID0MATERIAL\") == \"null\").count() > 0)\n",
    "# print(\"Article df statistics:\")\n",
    "# articles_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2cd2b",
   "metadata": {},
   "source": [
    "### I can observe ARTICLE_ID0MATERIAL is long. Lot of column values are having \"null\" string which can be converted to actual null values. There are no duplicate rows in article dataframe. Lot of column can make use of datatype change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6fa7a740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------+---------------------------+----------+--------------------+----------------------+--------------------+--------------------------------+-------------------+-------------------+\n",
      "|ARTICLE_ID0MATERIAL|ARTICLE_COLOR_ID0RT_COLOR|ARTICLE_GROUP_ID0RT_CONFMAT|EAN0EANUPC|   DESCRIPTION0TXTMD|BRAND_NAME/SOL/MDPROD1|PICTURE_PATH0EXT_URL|INITIAL_SEASON_NAME/SOL/FMSSEASO|CURRENT_SEASON_NAME|MATL_TYPE0MATL_TYPE|\n",
      "+-------------------+-------------------------+---------------------------+----------+--------------------+----------------------+--------------------+--------------------------------+-------------------+-------------------+\n",
      "| 000000000001282247|                     NULL|                       NULL|      NULL|d3dd68a11f543d039...|                    75|                NULL|                          202008|             202008|               ZMO3|\n",
      "| 000000000001282474|                     NULL|                       NULL|      NULL|d6045a9b489ed9fab...|                    75|                NULL|                          202010|             202010|               ZMO4|\n",
      "| 000000000002040465|                     NULL|                       NULL|      NULL|2200051f109fd164f...|                    10|                NULL|                          202007|             202008|               ZMO3|\n",
      "| 000000000002041285|                     NULL|                       NULL|      NULL|8a9eb4021fd0d70a8...|                    50|                NULL|                          202007|             202007|               ZMO3|\n",
      "| 000000000002041681|                     NULL|                       NULL|      NULL|eb1fb78047d6a068f...|                    10|                NULL|                          202008|             202008|               ZMO3|\n",
      "+-------------------+-------------------------+---------------------------+----------+--------------------+----------------------+--------------------+--------------------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace \"null\" strings with actual nulls\n",
    "cleaned_articles_df = articles_df.replace(\"null\", None)\n",
    "\n",
    "#Type conversion\n",
    "cleaned_articles_df = (\n",
    "    cleaned_articles_df\n",
    "      # numeric identifiers â†’ LongType\n",
    "      #.withColumn(\"ARTICLE_ID0MATERIAL\",   col(\"ARTICLE_ID0MATERIAL\").cast(LongType()))\n",
    "      #.withColumn(\"ARTICLE_GROUP_ID0RT_CONFMAT\", col(\"ARTICLE_GROUP_ID0RT_CONFMAT\").cast(LongType()))\n",
    "      .withColumn(\"EAN0EANUPC\", col(\"EAN0EANUPC\").cast(LongType()))\n",
    "      .withColumn(\"BRAND_NAME/SOL/MDPROD1\",     col(\"BRAND_NAME/SOL/MDPROD1\").cast(IntegerType()))\n",
    "      .withColumn(\"INITIAL_SEASON_NAME/SOL/FMSSEASO\",     col(\"INITIAL_SEASON_NAME/SOL/FMSSEASO\").cast(IntegerType()))\n",
    "      .withColumn(\"CURRENT_SEASON_NAME\",     col(\"CURRENT_SEASON_NAME\").cast(IntegerType()))\n",
    "\n",
    ")\n",
    "\n",
    "cleaned_articles_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c0212",
   "metadata": {},
   "source": [
    "### Nulls in article df before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "281ef159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'ARTICLE_ID0MATERIAL' NULL value count 0\n",
      "Column 'ARTICLE_COLOR_ID0RT_COLOR' NULL value count 0\n",
      "Column 'ARTICLE_GROUP_ID0RT_CONFMAT' NULL value count 0\n",
      "Column 'EAN0EANUPC' NULL value count 0\n",
      "Column 'DESCRIPTION0TXTMD' NULL value count 0\n",
      "Column 'BRAND_NAME/SOL/MDPROD1' NULL value count 0\n",
      "Column 'PICTURE_PATH0EXT_URL' NULL value count 0\n",
      "Column 'INITIAL_SEASON_NAME/SOL/FMSSEASO' NULL value count 0\n",
      "Column 'CURRENT_SEASON_NAME' NULL value count 0\n",
      "Column 'MATL_TYPE0MATL_TYPE' NULL value count 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# for each column c, produce sum of 1 where c IS NULL, else 0\n",
    "null_count_exprs = [\n",
    "    F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in articles_df.columns\n",
    "]\n",
    "row = articles_df.select(*null_count_exprs).first()\n",
    "null_counts = row.asDict()\n",
    "for column, count in null_counts.items():\n",
    "    print(f\"Column '{column}' NULL value count {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1d916a",
   "metadata": {},
   "source": [
    "### Nulls in cleaned article df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fd582423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'ARTICLE_ID0MATERIAL' NULL value count 0\n",
      "Column 'ARTICLE_COLOR_ID0RT_COLOR' NULL value count 18004\n",
      "Column 'ARTICLE_GROUP_ID0RT_CONFMAT' NULL value count 18004\n",
      "Column 'EAN0EANUPC' NULL value count 18004\n",
      "Column 'DESCRIPTION0TXTMD' NULL value count 0\n",
      "Column 'BRAND_NAME/SOL/MDPROD1' NULL value count 0\n",
      "Column 'PICTURE_PATH0EXT_URL' NULL value count 18004\n",
      "Column 'INITIAL_SEASON_NAME/SOL/FMSSEASO' NULL value count 0\n",
      "Column 'CURRENT_SEASON_NAME' NULL value count 0\n",
      "Column 'MATL_TYPE0MATL_TYPE' NULL value count 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for each column c, produce sum of 1 where c IS NULL, else 0\n",
    "null_count_exprs = [\n",
    "    F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in cleaned_articles_df.columns\n",
    "]\n",
    "row = cleaned_articles_df.select(*null_count_exprs).first()\n",
    "null_counts = row.asDict()\n",
    "for column, count in null_counts.items():\n",
    "    print(f\"Column '{column}' NULL value count {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e804e",
   "metadata": {},
   "source": [
    "### I tried converting ARTICLE_ID0MATERIAL and ARTICLE_GROUP_ID0RT_CONFMAT to Long and Int but the null count increased. Later I found there are characters in them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff897f6",
   "metadata": {},
   "source": [
    "## Transaction DF initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4d1738c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction DataFrame:\n",
      "+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "|TRANSACTION_ID/SOL/BONKEY|TRANSACTION_TIME0RPA_ETS2|SALESORG0SALESORG|TRANSACTION_DATE0CALDAY|DISTR_CHAN0DISTR_CHAN|ARTICLE_ID0MATERIAL|LOCATION_ID0PLANT|TRANSACTION_TYPE0RPA_TTC|ARTICLE_COUNT0RPA_RLQ|SALES_PRICE_AT_CASH_DESK0RPA_SAT|SALES_PRICE_PLANNED/SOL/LOC0086C|VAT0RPA_TAM|\n",
      "+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "|0002021040620240000000061|121315                   |1099             |20210406               |13                   |000000002062042026 |2024             |1005                    |1.000                |10.49                           |13.99                           |0.00       |\n",
      "|0002021040620330000000002|090059                   |1099             |20210406               |13                   |000000002058814001 |2033             |1005                    |1.000                |25.81                           |25.99                           |0.00       |\n",
      "|0002021040620390000000170|184446                   |1099             |20210406               |13                   |000000001259021005 |2039             |1001                    |1.000                |47.99                           |59.99                           |9.58       |\n",
      "|0002021040620400000000013|085239                   |1099             |20210406               |13                   |000000002060992002 |2040             |1005                    |1.000                |59.99                           |59.99                           |0.00       |\n",
      "|0002021040620520000000045|125059                   |1099             |20210406               |13                   |000000002058855023 |2052             |1005                    |1.000                |15.53                           |19.99                           |0.00       |\n",
      "+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Count of Transaction DataFrame: 14779\n",
      "Unique TRANSACTION_ID in Transaction DataFrame: 7430\n",
      "Duplicate TRANSACTION_ID/SOL/BONKEY rows: 3147\n",
      "Duplicate TRANSACTION_ID/SOL/BONKEY, ARTICLE_ID0MATERIAL rows: 0\n",
      "Unique TRANSACTION_ID, Article ID in Transaction DataFrame: 14779\n",
      "Is Article ID having null values? False\n",
      "Is Article ID having empty values? False\n",
      "Is Article ID having empty null strings? False\n",
      "Is Transaction ID having null values? False\n",
      "Is Transaction ID having empty values? False\n",
      "Is Transaction ID having empty null strings? False\n"
     ]
    }
   ],
   "source": [
    "print(\"Transaction DataFrame:\")\n",
    "transactions_df.show(5,truncate=False)\n",
    "# print(\"Transaction DataFrame Schema:\")\n",
    "# transactions_df.printSchema()\n",
    "print(\"Count of Transaction DataFrame:\", transactions_df.count())\n",
    "print(\"Unique TRANSACTION_ID in Transaction DataFrame:\", transactions_df.select(\"TRANSACTION_ID/SOL/BONKEY\").distinct().count())\n",
    "# 4.1 Check for duplicate keys in ARTICLE\n",
    "dup_transaction = transactions_df.groupBy(\"TRANSACTION_ID/SOL/BONKEY\").count().filter(col(\"count\") > 1)\n",
    "print(\"Duplicate TRANSACTION_ID/SOL/BONKEY rows:\", dup_transaction.count())\n",
    "dup_transaction = transactions_df.groupBy([\"TRANSACTION_ID/SOL/BONKEY\",\"ARTICLE_ID0MATERIAL\"]).count().filter(col(\"count\") > 1)\n",
    "print(\"Duplicate TRANSACTION_ID/SOL/BONKEY, ARTICLE_ID0MATERIAL rows:\", dup_transaction.count())\n",
    "print(\"Unique TRANSACTION_ID, Article ID in Transaction DataFrame:\", transactions_df.select([\"TRANSACTION_ID/SOL/BONKEY\", \"ARTICLE_ID0MATERIAL\"]).distinct().count())\n",
    "\n",
    "#dup_transaction_1 = cleaned_transactions_df.filter(cleaned_transactions_df['TRANSACTION_ID/SOL/BONKEY'] == '0002021040720240000000117' )\n",
    "#dup_transaction_1.show( truncate=False)\n",
    "\n",
    "print(\"Is Article ID having null values?\", transactions_df.filter(col(\"ARTICLE_ID0MATERIAL\").isNull()).count() > 0)\n",
    "print(\"Is Article ID having empty values?\", transactions_df.filter(col(\"ARTICLE_ID0MATERIAL\") == \"\").count() > 0)\n",
    "print(\"Is Article ID having empty null strings?\", transactions_df.filter(col(\"ARTICLE_ID0MATERIAL\") == \"null\").count() > 0)\n",
    "\n",
    "print(\"Is Transaction ID having null values?\", transactions_df.filter(col(\"TRANSACTION_ID/SOL/BONKEY\").isNull()).count() > 0)\n",
    "print(\"Is Transaction ID having empty values?\", transactions_df.filter(col(\"TRANSACTION_ID/SOL/BONKEY\") == \"\").count() > 0)\n",
    "print(\"Is Transaction ID having empty null strings?\", transactions_df.filter(col(\"TRANSACTION_ID/SOL/BONKEY\") == \"null\").count() > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4affa18e",
   "metadata": {},
   "source": [
    "### After analysis I found that the transaction data does not have any duplicate rows. It has a composite key (TRANSACTION_ID/SOL/BONKEY and ARTICLE_ID0MATERIAL). The data type of the coulmns needs to be defined explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f7023f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "|TRANSACTION_ID/SOL/BONKEY|TRANSACTION_TIME0RPA_ETS2|SALESORG0SALESORG|TRANSACTION_DATE0CALDAY|DISTR_CHAN0DISTR_CHAN|ARTICLE_ID0MATERIAL|LOCATION_ID0PLANT|TRANSACTION_TYPE0RPA_TTC|ARTICLE_COUNT0RPA_RLQ|SALES_PRICE_AT_CASH_DESK0RPA_SAT|SALES_PRICE_PLANNED/SOL/LOC0086C|VAT0RPA_TAM|\n",
      "+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "|0002021040620240000000061|121315                   |1099             |2021-04-06             |13                   |000000002062042026 |2024             |1005                    |1.000                |10.49                           |13.99                           |0.00       |\n",
      "|0002021040620330000000002|090059                   |1099             |2021-04-06             |13                   |000000002058814001 |2033             |1005                    |1.000                |25.81                           |25.99                           |0.00       |\n",
      "|0002021040620390000000170|184446                   |1099             |2021-04-06             |13                   |000000001259021005 |2039             |1001                    |1.000                |47.99                           |59.99                           |9.58       |\n",
      "|0002021040620400000000013|085239                   |1099             |2021-04-06             |13                   |000000002060992002 |2040             |1005                    |1.000                |59.99                           |59.99                           |0.00       |\n",
      "|0002021040620520000000045|125059                   |1099             |2021-04-06             |13                   |000000002058855023 |2052             |1005                    |1.000                |15.53                           |19.99                           |0.00       |\n",
      "+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- TRANSACTION_ID/SOL/BONKEY: string (nullable = true)\n",
      " |-- TRANSACTION_TIME0RPA_ETS2: string (nullable = true)\n",
      " |-- SALESORG0SALESORG: integer (nullable = true)\n",
      " |-- TRANSACTION_DATE0CALDAY: date (nullable = true)\n",
      " |-- DISTR_CHAN0DISTR_CHAN: integer (nullable = true)\n",
      " |-- ARTICLE_ID0MATERIAL: string (nullable = true)\n",
      " |-- LOCATION_ID0PLANT: integer (nullable = true)\n",
      " |-- TRANSACTION_TYPE0RPA_TTC: integer (nullable = true)\n",
      " |-- ARTICLE_COUNT0RPA_RLQ: string (nullable = true)\n",
      " |-- SALES_PRICE_AT_CASH_DESK0RPA_SAT: string (nullable = true)\n",
      " |-- SALES_PRICE_PLANNED/SOL/LOC0086C: string (nullable = true)\n",
      " |-- VAT0RPA_TAM: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace \"null\" strings with actual nulls\n",
    "cleaned_transactions_df = transactions_df.replace(\"null\", None)\n",
    "\n",
    "#Type conversion\n",
    "cleaned_transactions_df = (\n",
    "    cleaned_transactions_df\n",
    "      #.withColumn(\"TRANSACTION_ID/SOL/BONKEY\",   col(\"TRANSACTION_ID/SOL/BONKEY\").cast(LongType()))   Did not work, so left it as StringType\n",
    "      .withColumn(\"SALESORG0SALESORG\",     col(\"SALESORG0SALESORG\").cast(IntegerType()))\n",
    "      .withColumn(\"TRANSACTION_DATE0CALDAY\", to_date(col(\"TRANSACTION_DATE0CALDAY\"), \"yyyyMMdd\"))\n",
    "      .withColumn(\"DISTR_CHAN0DISTR_CHAN\",     col(\"DISTR_CHAN0DISTR_CHAN\").cast(IntegerType()))\n",
    "      #.withColumn(\"ARTICLE_ID0MATERIAL\",   col(\"ARTICLE_ID0MATERIAL\").cast(LongType()))\n",
    "      .withColumn(\"LOCATION_ID0PLANT\",     col(\"LOCATION_ID0PLANT\").cast(IntegerType()))\n",
    "      .withColumn(\"TRANSACTION_TYPE0RPA_TTC\",     col(\"TRANSACTION_TYPE0RPA_TTC\").cast(IntegerType()))\n",
    "      #.withColumn(\"ARTICLE_COUNT0RPA_RLQ\",     col(\"ARTICLE_COUNT0RPA_RLQ\").cast(IntegerType()))\n",
    "      #.withColumn(\"SALES_PRICE_AT_CASH_DESK0RPA_SAT\", col(\"SALES_PRICE_AT_CASH_DESK0RPA_SAT\").cast(DecimalType(10,2)))\n",
    "      #.withColumn(\"SALES_PRICE_PLANNED/SOL/LOC0086C\", col(\"SALES_PRICE_PLANNED/SOL/LOC0086C\").cast(DecimalType(10,2)))\n",
    "      #.withColumn(\"VAT0RPA_TAM\", col(\"VAT0RPA_TAM\").cast(DecimalType(10,2)))\n",
    "\n",
    ")\n",
    "\n",
    "cleaned_transactions_df.show(5, truncate=False)\n",
    "#cleaned_transactions_df.select(['ARTICLE_COUNT0RPA_RLQ']).distinct().show( truncate=False)\n",
    "\n",
    "cleaned_transactions_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e59f2",
   "metadata": {},
   "source": [
    "### Nulls in Transaction dataframe before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f42a4159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'TRANSACTION_ID/SOL/BONKEY' NULL value count 0\n",
      "Column 'TRANSACTION_TIME0RPA_ETS2' NULL value count 0\n",
      "Column 'SALESORG0SALESORG' NULL value count 0\n",
      "Column 'TRANSACTION_DATE0CALDAY' NULL value count 0\n",
      "Column 'DISTR_CHAN0DISTR_CHAN' NULL value count 0\n",
      "Column 'ARTICLE_ID0MATERIAL' NULL value count 0\n",
      "Column 'LOCATION_ID0PLANT' NULL value count 0\n",
      "Column 'TRANSACTION_TYPE0RPA_TTC' NULL value count 0\n",
      "Column 'ARTICLE_COUNT0RPA_RLQ' NULL value count 0\n",
      "Column 'SALES_PRICE_AT_CASH_DESK0RPA_SAT' NULL value count 0\n",
      "Column 'SALES_PRICE_PLANNED/SOL/LOC0086C' NULL value count 0\n",
      "Column 'VAT0RPA_TAM' NULL value count 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for each column c, produce sum of 1 where c IS NULL, else 0\n",
    "null_count_exprs = [\n",
    "    F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in transactions_df.columns\n",
    "]\n",
    "row = transactions_df.select(*null_count_exprs).first()\n",
    "null_counts = row.asDict()\n",
    "for column, count in null_counts.items():\n",
    "    print(f\"Column '{column}' NULL value count {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35a01a",
   "metadata": {},
   "source": [
    "### Nulls in transaction df after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "80b0333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'TRANSACTION_ID/SOL/BONKEY' NULL value count 0\n",
      "Column 'TRANSACTION_TIME0RPA_ETS2' NULL value count 0\n",
      "Column 'SALESORG0SALESORG' NULL value count 0\n",
      "Column 'TRANSACTION_DATE0CALDAY' NULL value count 0\n",
      "Column 'DISTR_CHAN0DISTR_CHAN' NULL value count 0\n",
      "Column 'ARTICLE_ID0MATERIAL' NULL value count 0\n",
      "Column 'LOCATION_ID0PLANT' NULL value count 0\n",
      "Column 'TRANSACTION_TYPE0RPA_TTC' NULL value count 0\n",
      "Column 'ARTICLE_COUNT0RPA_RLQ' NULL value count 0\n",
      "Column 'SALES_PRICE_AT_CASH_DESK0RPA_SAT' NULL value count 0\n",
      "Column 'SALES_PRICE_PLANNED/SOL/LOC0086C' NULL value count 0\n",
      "Column 'VAT0RPA_TAM' NULL value count 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for each column c, produce sum of 1 where c IS NULL, else 0\n",
    "null_count_exprs = [\n",
    "    F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in cleaned_transactions_df.columns\n",
    "]\n",
    "row = cleaned_transactions_df.select(*null_count_exprs).first()\n",
    "null_counts = row.asDict()\n",
    "for column, count in null_counts.items():\n",
    "    print(f\"Column '{column}' NULL value count {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea2899",
   "metadata": {},
   "source": [
    "### When I convert last 4 numeric column it some of the rows get's converted to null. After inspection I found that there are values like this 1.000-,31.99-,39.99-,5.11-. I undid the type conversion. Let's fix the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "418fd951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "|TRANSACTION_ID/SOL/BONKEY|TRANSACTION_TIME0RPA_ETS2|SALESORG0SALESORG|TRANSACTION_DATE0CALDAY|DISTR_CHAN0DISTR_CHAN|ARTICLE_ID0MATERIAL|LOCATION_ID0PLANT|TRANSACTION_TYPE0RPA_TTC|ARTICLE_COUNT0RPA_RLQ|SALES_PRICE_AT_CASH_DESK0RPA_SAT|SALES_PRICE_PLANNED/SOL/LOC0086C|VAT0RPA_TAM|\n",
      "+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "|     00020210406202400...|                   121315|             1099|             2021-04-06|                   13| 000000002062042026|             2024|                    1005|                1.000|                           10.49|                           13.99|       0.00|\n",
      "|     00020210406203300...|                   090059|             1099|             2021-04-06|                   13| 000000002058814001|             2033|                    1005|                1.000|                           25.81|                           25.99|       0.00|\n",
      "|     00020210406203900...|                   184446|             1099|             2021-04-06|                   13| 000000001259021005|             2039|                    1001|                1.000|                           47.99|                           59.99|       9.58|\n",
      "|     00020210406204000...|                   085239|             1099|             2021-04-06|                   13| 000000002060992002|             2040|                    1005|                1.000|                           59.99|                           59.99|       0.00|\n",
      "|     00020210406205200...|                   125059|             1099|             2021-04-06|                   13| 000000002058855023|             2052|                    1005|                1.000|                           15.53|                           19.99|       0.00|\n",
      "+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_transactions_df = cleaned_transactions_df.withColumn(\n",
    "    \"ARTICLE_COUNT0RPA_RLQ\",\n",
    "    when(\n",
    "        col(\"ARTICLE_COUNT0RPA_RLQ\").endswith(\"-\"),\n",
    "        # strip trailing '-' and prepend it to the number\n",
    "        F.concat(F.lit(\"-\"), F.regexp_replace(col(\"ARTICLE_COUNT0RPA_RLQ\"), r\"-$\", \"\")).cast(\"decimal(10, 3)\")\n",
    "    ).otherwise(\n",
    "        col(\"ARTICLE_COUNT0RPA_RLQ\").cast(\"decimal(10, 3)\")\n",
    "    )\n",
    ").withColumn(\n",
    "    \"SALES_PRICE_AT_CASH_DESK0RPA_SAT\",\n",
    "    when(\n",
    "        col(\"SALES_PRICE_AT_CASH_DESK0RPA_SAT\").endswith(\"-\"),\n",
    "        # strip trailing '-' and prepend it to the number\n",
    "        F.concat(F.lit(\"-\"), F.regexp_replace(col(\"SALES_PRICE_AT_CASH_DESK0RPA_SAT\"), r\"-$\", \"\")).cast(\"decimal(10, 2)\")\n",
    "    ).otherwise(\n",
    "        col(\"SALES_PRICE_AT_CASH_DESK0RPA_SAT\").cast(\"decimal(10, 2)\")\n",
    "    )\n",
    ").withColumn(\n",
    "    \"SALES_PRICE_PLANNED/SOL/LOC0086C\",\n",
    "    when(\n",
    "        col(\"SALES_PRICE_PLANNED/SOL/LOC0086C\").endswith(\"-\"),\n",
    "        # strip trailing '-' and prepend it to the number\n",
    "        F.concat(F.lit(\"-\"), F.regexp_replace(col(\"SALES_PRICE_PLANNED/SOL/LOC0086C\"), r\"-$\", \"\")).cast(\"decimal(10, 2)\")\n",
    "    ).otherwise(\n",
    "        col(\"SALES_PRICE_PLANNED/SOL/LOC0086C\").cast(\"decimal(10, 2)\")\n",
    "    )\n",
    ").withColumn(\n",
    "    \"VAT0RPA_TAM\",\n",
    "    when(\n",
    "        col(\"VAT0RPA_TAM\").endswith(\"-\"),\n",
    "        # strip trailing '-' and prepend it to the number\n",
    "        F.concat(F.lit(\"-\"), F.regexp_replace(col(\"VAT0RPA_TAM\"), r\"-$\", \"\")).cast(\"decimal(10, 2)\")\n",
    "    ).otherwise(\n",
    "        col(\"VAT0RPA_TAM\").cast(\"decimal(10, 2)\")\n",
    "    )\n",
    ")\n",
    "\n",
    "cleaned_transactions_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06bae3",
   "metadata": {},
   "source": [
    "### Null values after the fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b1735107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'TRANSACTION_ID/SOL/BONKEY' NULL value count 0\n",
      "Column 'TRANSACTION_TIME0RPA_ETS2' NULL value count 0\n",
      "Column 'SALESORG0SALESORG' NULL value count 0\n",
      "Column 'TRANSACTION_DATE0CALDAY' NULL value count 0\n",
      "Column 'DISTR_CHAN0DISTR_CHAN' NULL value count 0\n",
      "Column 'ARTICLE_ID0MATERIAL' NULL value count 0\n",
      "Column 'LOCATION_ID0PLANT' NULL value count 0\n",
      "Column 'TRANSACTION_TYPE0RPA_TTC' NULL value count 0\n",
      "Column 'ARTICLE_COUNT0RPA_RLQ' NULL value count 0\n",
      "Column 'SALES_PRICE_AT_CASH_DESK0RPA_SAT' NULL value count 0\n",
      "Column 'SALES_PRICE_PLANNED/SOL/LOC0086C' NULL value count 0\n",
      "Column 'VAT0RPA_TAM' NULL value count 0\n",
      "root\n",
      " |-- TRANSACTION_ID/SOL/BONKEY: string (nullable = true)\n",
      " |-- TRANSACTION_TIME0RPA_ETS2: string (nullable = true)\n",
      " |-- SALESORG0SALESORG: integer (nullable = true)\n",
      " |-- TRANSACTION_DATE0CALDAY: date (nullable = true)\n",
      " |-- DISTR_CHAN0DISTR_CHAN: integer (nullable = true)\n",
      " |-- ARTICLE_ID0MATERIAL: string (nullable = true)\n",
      " |-- LOCATION_ID0PLANT: integer (nullable = true)\n",
      " |-- TRANSACTION_TYPE0RPA_TTC: integer (nullable = true)\n",
      " |-- ARTICLE_COUNT0RPA_RLQ: decimal(10,3) (nullable = true)\n",
      " |-- SALES_PRICE_AT_CASH_DESK0RPA_SAT: decimal(10,2) (nullable = true)\n",
      " |-- SALES_PRICE_PLANNED/SOL/LOC0086C: decimal(10,2) (nullable = true)\n",
      " |-- VAT0RPA_TAM: decimal(10,2) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# for each column c, produce sum of 1 where c IS NULL, else 0\n",
    "null_count_exprs = [\n",
    "    F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in cleaned_transactions_df.columns\n",
    "]\n",
    "row = cleaned_transactions_df.select(*null_count_exprs).first()\n",
    "null_counts = row.asDict()\n",
    "for column, count in null_counts.items():\n",
    "    print(f\"Column '{column}' NULL value count {count}\")\n",
    "\n",
    "\n",
    "cleaned_transactions_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068907d",
   "metadata": {},
   "source": [
    "### The \"-\" at the end of last 4 columns were fixed as it were negative numerical values and the type conversion was success full."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe774a97",
   "metadata": {},
   "source": [
    "## Let's join the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "39befa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+-------------------------+---------------------------+-------------+----------------------------------------+----------------------+----------------------------------------+--------------------------------+-------------------+-------------------+\n",
      "|ARTICLE_ID0MATERIAL|TRANSACTION_ID/SOL/BONKEY|TRANSACTION_TIME0RPA_ETS2|SALESORG0SALESORG|TRANSACTION_DATE0CALDAY|DISTR_CHAN0DISTR_CHAN|LOCATION_ID0PLANT|TRANSACTION_TYPE0RPA_TTC|ARTICLE_COUNT0RPA_RLQ|SALES_PRICE_AT_CASH_DESK0RPA_SAT|SALES_PRICE_PLANNED/SOL/LOC0086C|VAT0RPA_TAM|ARTICLE_COLOR_ID0RT_COLOR|ARTICLE_GROUP_ID0RT_CONFMAT|EAN0EANUPC   |DESCRIPTION0TXTMD                       |BRAND_NAME/SOL/MDPROD1|PICTURE_PATH0EXT_URL                    |INITIAL_SEASON_NAME/SOL/FMSSEASO|CURRENT_SEASON_NAME|MATL_TYPE0MATL_TYPE|\n",
      "+-------------------+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+-------------------------+---------------------------+-------------+----------------------------------------+----------------------+----------------------------------------+--------------------------------+-------------------+-------------------+\n",
      "|000000001192021001 |0002021040641630000000025|114928                   |1099             |2021-04-06             |13                   |4163             |1005                    |1.000                |14.78                           |19.99                           |0.00       |0100                     |000000000001192021         |4057117184730|9a47b4f28ef2c6e26c8bd03ecfe143fc6652a44b|10                    |357a0984e0ea6d38a8f72202a51eaf480cb1a2a8|201602                          |202008             |ZMO3               |\n",
      "|000000001192021001 |0002021040773370000000077|161018                   |1099             |2021-04-07             |13                   |7337             |1005                    |1.000                |14.99                           |19.99                           |0.00       |0100                     |000000000001192021         |4057117184730|9a47b4f28ef2c6e26c8bd03ecfe143fc6652a44b|10                    |357a0984e0ea6d38a8f72202a51eaf480cb1a2a8|201602                          |202008             |ZMO3               |\n",
      "|000000001192021005 |0002021040620240000000161|173837                   |1099             |2021-04-06             |13                   |2024             |1005                    |1.000                |14.99                           |19.99                           |0.00       |0100                     |000000000001192021         |4057117184754|9a47b4f28ef2c6e26c8bd03ecfe143fc6652a44b|10                    |357a0984e0ea6d38a8f72202a51eaf480cb1a2a8|201602                          |202008             |ZMO3               |\n",
      "|000000001192021005 |0002021040820240000000195|183027                   |1099             |2021-04-08             |13                   |2024             |1005                    |1.000                |14.99                           |19.99                           |0.00       |0100                     |000000000001192021         |4057117184754|9a47b4f28ef2c6e26c8bd03ecfe143fc6652a44b|10                    |357a0984e0ea6d38a8f72202a51eaf480cb1a2a8|201602                          |202008             |ZMO3               |\n",
      "|000000002040417004 |0002021040620490000000069|112635                   |1099             |2021-04-06             |13                   |2049             |1005                    |1.000                |31.99                           |39.99                           |0.00       |9999                     |000000000002040417         |4063614066738|9cb941b2e3de1dce69c0f6df05ebad0d7b80b38d|10                    |256ad54ed4da351e9f56657c98bc8734bd05e54c|202009                          |202009             |ZMO3               |\n",
      "+-------------------+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+-------------------------+---------------------------+-------------+----------------------------------------+----------------------+----------------------------------------+--------------------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in TARGET: 0\n",
      "Count of Transaction DataFrame: 14779\n",
      "Count of Joined Article Transaction DataFrame: 7184\n",
      "Unique  TRANSACTION_ID, Article ID in Joined Article Transaction DataFrame: 7184\n",
      "root\n",
      " |-- ARTICLE_ID0MATERIAL: string (nullable = true)\n",
      " |-- TRANSACTION_ID/SOL/BONKEY: string (nullable = true)\n",
      " |-- TRANSACTION_TIME0RPA_ETS2: string (nullable = true)\n",
      " |-- SALESORG0SALESORG: integer (nullable = true)\n",
      " |-- TRANSACTION_DATE0CALDAY: date (nullable = true)\n",
      " |-- DISTR_CHAN0DISTR_CHAN: integer (nullable = true)\n",
      " |-- LOCATION_ID0PLANT: integer (nullable = true)\n",
      " |-- TRANSACTION_TYPE0RPA_TTC: integer (nullable = true)\n",
      " |-- ARTICLE_COUNT0RPA_RLQ: decimal(10,3) (nullable = true)\n",
      " |-- SALES_PRICE_AT_CASH_DESK0RPA_SAT: decimal(10,2) (nullable = true)\n",
      " |-- SALES_PRICE_PLANNED/SOL/LOC0086C: decimal(10,2) (nullable = true)\n",
      " |-- VAT0RPA_TAM: decimal(10,2) (nullable = true)\n",
      " |-- ARTICLE_COLOR_ID0RT_COLOR: string (nullable = true)\n",
      " |-- ARTICLE_GROUP_ID0RT_CONFMAT: string (nullable = true)\n",
      " |-- EAN0EANUPC: long (nullable = true)\n",
      " |-- DESCRIPTION0TXTMD: string (nullable = true)\n",
      " |-- BRAND_NAME/SOL/MDPROD1: integer (nullable = true)\n",
      " |-- PICTURE_PATH0EXT_URL: string (nullable = true)\n",
      " |-- INITIAL_SEASON_NAME/SOL/FMSSEASO: integer (nullable = true)\n",
      " |-- CURRENT_SEASON_NAME: integer (nullable = true)\n",
      " |-- MATL_TYPE0MATL_TYPE: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "article_transaction_df = cleaned_transactions_df.join(\n",
    "    cleaned_articles_df,\n",
    "    on=\"ARTICLE_ID0MATERIAL\",\n",
    "    how=\"inner\" # When used Inner join the row drops to \n",
    ")\n",
    "article_transaction_df.show(5, truncate=False)\n",
    "\n",
    "# Ensure no duplicates in TARGET \n",
    "dup_target = article_transaction_df.groupBy(article_transaction_df.columns).count().filter(col(\"count\") > 1)\n",
    "print(\"Duplicate rows in TARGET:\", dup_target.count())\n",
    "\n",
    "print(\"Count of Transaction DataFrame:\", cleaned_transactions_df.count())\n",
    "print(\"Count of Joined Article Transaction DataFrame:\", article_transaction_df.count())\n",
    "print(\"Unique  TRANSACTION_ID, Article ID in Joined Article Transaction DataFrame:\", article_transaction_df.select([\"TRANSACTION_ID/SOL/BONKEY\", \"ARTICLE_ID0MATERIAL\"]).distinct().count())\n",
    "\n",
    "\n",
    "article_transaction_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5aecd0",
   "metadata": {},
   "source": [
    "### When we do a inner join, the target df count drops to 7184. Let's find the article ids which are not present in the article dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "67f4eaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Transactions with no matching ARTICLE: 7595\n",
      "Total count of transactions: 14779\n",
      "Total of missing and non-missing articles in TRANSACTIONS: 14779\n",
      "Transactions with no matching ARTICLE:\n",
      "+-------------------+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "|ARTICLE_ID0MATERIAL|TRANSACTION_ID/SOL/BONKEY|TRANSACTION_TIME0RPA_ETS2|SALESORG0SALESORG|TRANSACTION_DATE0CALDAY|DISTR_CHAN0DISTR_CHAN|LOCATION_ID0PLANT|TRANSACTION_TYPE0RPA_TTC|ARTICLE_COUNT0RPA_RLQ|SALES_PRICE_AT_CASH_DESK0RPA_SAT|SALES_PRICE_PLANNED/SOL/LOC0086C|VAT0RPA_TAM|\n",
      "+-------------------+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "| 000000002062042026|     00020210406202400...|                   121315|             1099|             2021-04-06|                   13|             2024|                    1005|                1.000|                           10.49|                           13.99|       0.00|\n",
      "| 000000001259021005|     00020210406203900...|                   184446|             1099|             2021-04-06|                   13|             2039|                    1001|                1.000|                           47.99|                           59.99|       9.58|\n",
      "| 000000002058855023|     00020210406205200...|                   125059|             1099|             2021-04-06|                   13|             2052|                    1005|                1.000|                           15.53|                           19.99|       0.00|\n",
      "| 000000002063182029|     00020210406205500...|                   122126|             1099|             2021-04-06|                   13|             2055|                    1005|                1.000|                           22.31|                           29.98|       0.00|\n",
      "| 000000006002412003|     00020210406207000...|                   160301|             1099|             2021-04-06|                   13|             2070|                    1001|                1.000|                            6.00|                            7.99|       0.96|\n",
      "+-------------------+-------------------------+-------------------------+-----------------+-----------------------+---------------------+-----------------+------------------------+---------------------+--------------------------------+--------------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Check for missing articles in TRANSACTIONS\n",
    "missing_articles = cleaned_transactions_df.join(cleaned_articles_df, on='ARTICLE_ID0MATERIAL', how='left_anti')\n",
    "\n",
    "#Print count of missing articles\n",
    "print(\"Count of Transactions with no matching ARTICLE:\", missing_articles.count())\n",
    "\n",
    "print(\"Total count of transactions:\", cleaned_transactions_df.count())\n",
    "print(\"Total of missing and non-missing articles in TRANSACTIONS:\", article_transaction_df.count() + missing_articles.count())\n",
    "\n",
    "print(\"Transactions with no matching ARTICLE:\")\n",
    "missing_articles.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d036d723",
   "metadata": {},
   "source": [
    "### Let's write the final tables as parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "28a3f315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "article_transaction_df.coalesce(1).write.mode(\"overwrite\").parquet('../article_transaction/')\n",
    "missing_articles.coalesce(1).write.mode(\"overwrite\").parquet('../missing_articles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qvc-dataengineering-bK_VmtfF-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
